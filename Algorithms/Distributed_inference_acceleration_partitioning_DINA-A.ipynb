{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Image : 1\n",
      "torch.Size([1, 3, 227, 227])\n",
      "=> Convolutional partition\n",
      "Part 1: (0, 92)\n",
      "Part 2: (90, 227)\n",
      "=> Fully-connected partition\n",
      "Part 1: (0, 90)\n",
      "Part 2: (90, 227)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/home/arnab/Desktop/dnn-offloading/Models/bdddataloader.py\")\n",
    "bddloader = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(bddloader)\n",
    "\n",
    "\n",
    "def partition(NN,img,k,CA,f):\n",
    "    # intializing variables\n",
    "    A = None\n",
    "    partition_size = []\n",
    "    batch = img.shape[0]\n",
    "    channel = img.shape[1]\n",
    "    W = [0] * k  # partition\n",
    "    Windex = []  # partitioning indexes\n",
    "    init = [0] * (k + 1)\n",
    "    CA[0] = 0\n",
    "    CA = [float(val) for val in CA]\n",
    "\n",
    "    r = img.shape[2]\n",
    "    c = img.shape[3]\n",
    "    \n",
    "    if r > c:\n",
    "        m = r\n",
    "    else:\n",
    "        m = c\n",
    "    \n",
    "    \n",
    "    # sum of capabilities of all nodes\n",
    "    C2 = np.sum(CA[:(k + 1)])\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        C1 = np.sum(CA[:i+1])\n",
    "        Pi = C1 / C2\n",
    "        if NN == \"conv\":\n",
    "            init[i] = math.floor(Pi * (m - (f - 1)))\n",
    "            partition_size.append((init[i-1],init[i]+(f-1)))\n",
    "        elif NN == \"ff\":\n",
    "            init[i] = math.floor(Pi * m)\n",
    "            partition_size.append((init[i - 1],init[i]))\n",
    "\n",
    "    return partition_size\n",
    "    \n",
    "def main():\n",
    "    # initialize variables\n",
    "    BATCH_SIZE = 1\n",
    "    IMAGE_DIM = 227\n",
    "    kernel = 3\n",
    "    worker = 2\n",
    "    CA = [0,4,6]\n",
    "    \n",
    "    # load images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(IMAGE_DIM),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "    \n",
    "    loader = data.DataLoader(\n",
    "        bddloader.BDDDataset('/home/arnab/Desktop/Data', train=True, transform=transform),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True)\n",
    "    \n",
    "    inx = 0\n",
    "    for img,level in loader:\n",
    "        print(\"=> Image : {}\".format(inx+1))\n",
    "        print(img.size())\n",
    "        after_part = partition(\"conv\",img,worker,CA,kernel)\n",
    "        print(f\"=> Convolutional partition\")\n",
    "        for j in range(len(after_part)):\n",
    "            print(f\"Part {j+1}: {after_part[j]}\")\n",
    "        \n",
    "        print(f\"=> Fully-connected partition\")\n",
    "        after_part = partition(\"ff\",img,worker,CA,0)\n",
    "        for j in range(len(after_part)):\n",
    "            print(f\"Part {j+1}: {after_part[j]}\")\n",
    "            \n",
    "        break # one image break\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
