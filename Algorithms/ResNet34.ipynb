{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: torch.Size([1, 3, 224, 224])\n",
      "After: torch.Size([1, 64, 56, 56])\n",
      "Before: torch.Size([1, 64, 56, 56])\n",
      "After: torch.Size([1, 64, 56, 56])\n",
      "Before: torch.Size([1, 64, 56, 56])\n",
      "After: torch.Size([1, 64, 56, 56])\n",
      "Before: torch.Size([1, 64, 56, 56])\n",
      "After: torch.Size([1, 64, 56, 56])\n",
      "Before: torch.Size([1, 64, 56, 56])\n",
      "After: torch.Size([1, 128, 28, 28])\n",
      "Before: torch.Size([1, 128, 28, 28])\n",
      "After: torch.Size([1, 128, 28, 28])\n",
      "Before: torch.Size([1, 128, 28, 28])\n",
      "After: torch.Size([1, 128, 28, 28])\n",
      "Before: torch.Size([1, 128, 28, 28])\n",
      "After: torch.Size([1, 128, 28, 28])\n",
      "Before: torch.Size([1, 128, 28, 28])\n",
      "After: torch.Size([1, 256, 14, 14])\n",
      "Before: torch.Size([1, 256, 14, 14])\n",
      "After: torch.Size([1, 256, 14, 14])\n",
      "Before: torch.Size([1, 256, 14, 14])\n",
      "After: torch.Size([1, 256, 14, 14])\n",
      "Before: torch.Size([1, 256, 14, 14])\n",
      "After: torch.Size([1, 256, 14, 14])\n",
      "Before: torch.Size([1, 256, 14, 14])\n",
      "After: torch.Size([1, 256, 14, 14])\n",
      "Before: torch.Size([1, 256, 14, 14])\n",
      "After: torch.Size([1, 256, 14, 14])\n",
      "Before: torch.Size([1, 256, 14, 14])\n",
      "After: torch.Size([1, 512, 7, 7])\n",
      "Before: torch.Size([1, 512, 7, 7])\n",
      "After: torch.Size([1, 512, 7, 7])\n",
      "Before: torch.Size([1, 512, 7, 7])\n",
      "After: torch.Size([1, 512, 7, 7])\n",
      "Before: torch.Size([1, 512, 7, 7])\n",
      "After: torch.Size([1, 512, 1, 1])\n",
      "Before: torch.Size([1, 512])\n",
      "After: torch.Size([1, 12])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/km1414/CNN-models/blob/master/resnet-32/resnet-32.py\n",
    "# https://github.com/safwankdb/ResNet34-TF2/blob/master/model.py\n",
    "# https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super(Block, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        \n",
    "        if (in_channels != out_channels) or stride > 1:\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size = 1, bias = False, stride = stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias = False, stride = stride),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        \n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"Before: {}\".format(x.size()))\n",
    "        if self.in_channels != self.out_channels or self.stride > 1:\n",
    "            out1 = self.features(x)\n",
    "            out2 = self.skip_connection(x)\n",
    "            print(\"After: {}\".format((out1+out2).size()))\n",
    "            return self.activation(out1+out2)\n",
    "        else:\n",
    "            out1 = self.features(x)\n",
    "            print(\"After: {}\".format((out1+x).size()))\n",
    "            return self.activation(out1+x)\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, num_classes = 12):\n",
    "        super(ResNet34, self).__init__()\n",
    "       \n",
    "        # 1st block\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.activation1 = nn.ReLU(inplace = True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding = 1)\n",
    "        \n",
    "        # 2nd block\n",
    "        self.conv2_1 = Block(in_channels = 64, out_channels = 64)\n",
    "        self.conv2_2 = Block(in_channels = 64, out_channels = 64)\n",
    "        self.conv2_3 = Block(in_channels = 64, out_channels = 64)\n",
    "        \n",
    "        # 3rd block\n",
    "        self.conv3_1 = Block(in_channels = 64, out_channels = 128, stride = 2)\n",
    "        self.conv3_2 = Block(in_channels = 128, out_channels = 128)\n",
    "        self.conv3_3 = Block(in_channels = 128, out_channels = 128)\n",
    "        self.conv3_4 = Block(in_channels = 128, out_channels = 128)\n",
    "        \n",
    "        # 4th block\n",
    "        self.conv4_1 = Block(in_channels = 128, out_channels = 256, stride = 2)\n",
    "        self.conv4_2 = Block(in_channels = 256, out_channels = 256)\n",
    "        self.conv4_3 = Block(in_channels = 256, out_channels = 256)\n",
    "        self.conv4_4 = Block(in_channels = 256, out_channels = 256)\n",
    "        self.conv4_5 = Block(in_channels = 256, out_channels = 256)\n",
    "        self.conv4_6 = Block(in_channels = 256, out_channels = 256)\n",
    "        \n",
    "        # 5th block\n",
    "        self.conv5_1 = Block(in_channels = 256, out_channels = 512, stride = 2)\n",
    "        self.conv5_2 = Block(in_channels = 512, out_channels = 512)\n",
    "        self.conv5_3 = Block(in_channels = 512, out_channels = 512)\n",
    "        \n",
    "        # avg pool\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully connected\n",
    "        self.ff = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1st block\n",
    "        print(\"Before: {}\".format(x.size()))\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.pool1(x)\n",
    "        print(\"After: {}\".format(x.size()))\n",
    "        \n",
    "        # 2nd block\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.conv2_3(x)\n",
    "        \n",
    "        # 3rd block\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.conv3_4(x)\n",
    "        \n",
    "        # 4th block\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.conv4_4(x)\n",
    "        x = self.conv4_5(x)\n",
    "        x = self.conv4_6(x)\n",
    "        \n",
    "        # 5th block\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = self.conv5_3(x)\n",
    "        \n",
    "        # avg pool\n",
    "        print(\"Before: {}\".format(x.size()))\n",
    "        x = self.pool2(x)\n",
    "        print(\"After: {}\".format(x.size()))\n",
    "        \n",
    "        # flatten\n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        # ff connected\n",
    "        print(\"Before: {}\".format(x.size()))\n",
    "        x = self.ff(x)\n",
    "        print(\"After: {}\".format(x.size()))\n",
    "        return x\n",
    "    \n",
    "\n",
    "def main():\n",
    "    net = ResNet34()\n",
    "    img = torch.Tensor(np.random.randn(1,3,224,224))\n",
    "    out = net(img)\n",
    "    print(out.size())\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0--------\n",
      "0 conv1.weight\n",
      "1 bn1.weight\n",
      "2 bn1.bias\n",
      "3 bn1.running_mean\n",
      "4 bn1.running_var\n",
      "5 bn1.num_batches_tracked\n",
      "1--------\n",
      "6 layer1.0.conv1.weight\n",
      "7 layer1.0.bn1.weight\n",
      "8 layer1.0.bn1.bias\n",
      "9 layer1.0.bn1.running_mean\n",
      "10 layer1.0.bn1.running_var\n",
      "11 layer1.0.bn1.num_batches_tracked\n",
      "2--------\n",
      "12 layer1.0.conv2.weight\n",
      "13 layer1.0.bn2.weight\n",
      "14 layer1.0.bn2.bias\n",
      "15 layer1.0.bn2.running_mean\n",
      "16 layer1.0.bn2.running_var\n",
      "17 layer1.0.bn2.num_batches_tracked\n",
      "3--------\n",
      "18 layer1.1.conv1.weight\n",
      "19 layer1.1.bn1.weight\n",
      "20 layer1.1.bn1.bias\n",
      "21 layer1.1.bn1.running_mean\n",
      "22 layer1.1.bn1.running_var\n",
      "23 layer1.1.bn1.num_batches_tracked\n",
      "4--------\n",
      "24 layer1.1.conv2.weight\n",
      "25 layer1.1.bn2.weight\n",
      "26 layer1.1.bn2.bias\n",
      "27 layer1.1.bn2.running_mean\n",
      "28 layer1.1.bn2.running_var\n",
      "29 layer1.1.bn2.num_batches_tracked\n",
      "5--------\n",
      "30 layer1.2.conv1.weight\n",
      "31 layer1.2.bn1.weight\n",
      "32 layer1.2.bn1.bias\n",
      "33 layer1.2.bn1.running_mean\n",
      "34 layer1.2.bn1.running_var\n",
      "35 layer1.2.bn1.num_batches_tracked\n",
      "6--------\n",
      "36 layer1.2.conv2.weight\n",
      "37 layer1.2.bn2.weight\n",
      "38 layer1.2.bn2.bias\n",
      "39 layer1.2.bn2.running_mean\n",
      "40 layer1.2.bn2.running_var\n",
      "41 layer1.2.bn2.num_batches_tracked\n",
      "7--------\n",
      "42 layer2.0.conv1.weight\n",
      "43 layer2.0.bn1.weight\n",
      "44 layer2.0.bn1.bias\n",
      "45 layer2.0.bn1.running_mean\n",
      "46 layer2.0.bn1.running_var\n",
      "47 layer2.0.bn1.num_batches_tracked\n",
      "8--------\n",
      "48 layer2.0.conv2.weight\n",
      "49 layer2.0.bn2.weight\n",
      "50 layer2.0.bn2.bias\n",
      "51 layer2.0.bn2.running_mean\n",
      "52 layer2.0.bn2.running_var\n",
      "53 layer2.0.bn2.num_batches_tracked\n",
      "9--------\n",
      "54 layer2.0.downsample.0.weight\n",
      "55 layer2.0.downsample.1.weight\n",
      "56 layer2.0.downsample.1.bias\n",
      "57 layer2.0.downsample.1.running_mean\n",
      "58 layer2.0.downsample.1.running_var\n",
      "59 layer2.0.downsample.1.num_batches_tracked\n",
      "10--------\n",
      "60 layer2.1.conv1.weight\n",
      "61 layer2.1.bn1.weight\n",
      "62 layer2.1.bn1.bias\n",
      "63 layer2.1.bn1.running_mean\n",
      "64 layer2.1.bn1.running_var\n",
      "65 layer2.1.bn1.num_batches_tracked\n",
      "11--------\n",
      "66 layer2.1.conv2.weight\n",
      "67 layer2.1.bn2.weight\n",
      "68 layer2.1.bn2.bias\n",
      "69 layer2.1.bn2.running_mean\n",
      "70 layer2.1.bn2.running_var\n",
      "71 layer2.1.bn2.num_batches_tracked\n",
      "12--------\n",
      "72 layer2.2.conv1.weight\n",
      "73 layer2.2.bn1.weight\n",
      "74 layer2.2.bn1.bias\n",
      "75 layer2.2.bn1.running_mean\n",
      "76 layer2.2.bn1.running_var\n",
      "77 layer2.2.bn1.num_batches_tracked\n",
      "13--------\n",
      "78 layer2.2.conv2.weight\n",
      "79 layer2.2.bn2.weight\n",
      "80 layer2.2.bn2.bias\n",
      "81 layer2.2.bn2.running_mean\n",
      "82 layer2.2.bn2.running_var\n",
      "83 layer2.2.bn2.num_batches_tracked\n",
      "14--------\n",
      "84 layer2.3.conv1.weight\n",
      "85 layer2.3.bn1.weight\n",
      "86 layer2.3.bn1.bias\n",
      "87 layer2.3.bn1.running_mean\n",
      "88 layer2.3.bn1.running_var\n",
      "89 layer2.3.bn1.num_batches_tracked\n",
      "15--------\n",
      "90 layer2.3.conv2.weight\n",
      "91 layer2.3.bn2.weight\n",
      "92 layer2.3.bn2.bias\n",
      "93 layer2.3.bn2.running_mean\n",
      "94 layer2.3.bn2.running_var\n",
      "95 layer2.3.bn2.num_batches_tracked\n",
      "16--------\n",
      "96 layer3.0.conv1.weight\n",
      "97 layer3.0.bn1.weight\n",
      "98 layer3.0.bn1.bias\n",
      "99 layer3.0.bn1.running_mean\n",
      "100 layer3.0.bn1.running_var\n",
      "101 layer3.0.bn1.num_batches_tracked\n",
      "17--------\n",
      "102 layer3.0.conv2.weight\n",
      "103 layer3.0.bn2.weight\n",
      "104 layer3.0.bn2.bias\n",
      "105 layer3.0.bn2.running_mean\n",
      "106 layer3.0.bn2.running_var\n",
      "107 layer3.0.bn2.num_batches_tracked\n",
      "18--------\n",
      "108 layer3.0.downsample.0.weight\n",
      "109 layer3.0.downsample.1.weight\n",
      "110 layer3.0.downsample.1.bias\n",
      "111 layer3.0.downsample.1.running_mean\n",
      "112 layer3.0.downsample.1.running_var\n",
      "113 layer3.0.downsample.1.num_batches_tracked\n",
      "19--------\n",
      "114 layer3.1.conv1.weight\n",
      "115 layer3.1.bn1.weight\n",
      "116 layer3.1.bn1.bias\n",
      "117 layer3.1.bn1.running_mean\n",
      "118 layer3.1.bn1.running_var\n",
      "119 layer3.1.bn1.num_batches_tracked\n",
      "20--------\n",
      "120 layer3.1.conv2.weight\n",
      "121 layer3.1.bn2.weight\n",
      "122 layer3.1.bn2.bias\n",
      "123 layer3.1.bn2.running_mean\n",
      "124 layer3.1.bn2.running_var\n",
      "125 layer3.1.bn2.num_batches_tracked\n",
      "21--------\n",
      "126 layer3.2.conv1.weight\n",
      "127 layer3.2.bn1.weight\n",
      "128 layer3.2.bn1.bias\n",
      "129 layer3.2.bn1.running_mean\n",
      "130 layer3.2.bn1.running_var\n",
      "131 layer3.2.bn1.num_batches_tracked\n",
      "22--------\n",
      "132 layer3.2.conv2.weight\n",
      "133 layer3.2.bn2.weight\n",
      "134 layer3.2.bn2.bias\n",
      "135 layer3.2.bn2.running_mean\n",
      "136 layer3.2.bn2.running_var\n",
      "137 layer3.2.bn2.num_batches_tracked\n",
      "23--------\n",
      "138 layer3.3.conv1.weight\n",
      "139 layer3.3.bn1.weight\n",
      "140 layer3.3.bn1.bias\n",
      "141 layer3.3.bn1.running_mean\n",
      "142 layer3.3.bn1.running_var\n",
      "143 layer3.3.bn1.num_batches_tracked\n",
      "24--------\n",
      "144 layer3.3.conv2.weight\n",
      "145 layer3.3.bn2.weight\n",
      "146 layer3.3.bn2.bias\n",
      "147 layer3.3.bn2.running_mean\n",
      "148 layer3.3.bn2.running_var\n",
      "149 layer3.3.bn2.num_batches_tracked\n",
      "25--------\n",
      "150 layer3.4.conv1.weight\n",
      "151 layer3.4.bn1.weight\n",
      "152 layer3.4.bn1.bias\n",
      "153 layer3.4.bn1.running_mean\n",
      "154 layer3.4.bn1.running_var\n",
      "155 layer3.4.bn1.num_batches_tracked\n",
      "26--------\n",
      "156 layer3.4.conv2.weight\n",
      "157 layer3.4.bn2.weight\n",
      "158 layer3.4.bn2.bias\n",
      "159 layer3.4.bn2.running_mean\n",
      "160 layer3.4.bn2.running_var\n",
      "161 layer3.4.bn2.num_batches_tracked\n",
      "27--------\n",
      "162 layer3.5.conv1.weight\n",
      "163 layer3.5.bn1.weight\n",
      "164 layer3.5.bn1.bias\n",
      "165 layer3.5.bn1.running_mean\n",
      "166 layer3.5.bn1.running_var\n",
      "167 layer3.5.bn1.num_batches_tracked\n",
      "28--------\n",
      "168 layer3.5.conv2.weight\n",
      "169 layer3.5.bn2.weight\n",
      "170 layer3.5.bn2.bias\n",
      "171 layer3.5.bn2.running_mean\n",
      "172 layer3.5.bn2.running_var\n",
      "173 layer3.5.bn2.num_batches_tracked\n",
      "29--------\n",
      "174 layer4.0.conv1.weight\n",
      "175 layer4.0.bn1.weight\n",
      "176 layer4.0.bn1.bias\n",
      "177 layer4.0.bn1.running_mean\n",
      "178 layer4.0.bn1.running_var\n",
      "179 layer4.0.bn1.num_batches_tracked\n",
      "30--------\n",
      "180 layer4.0.conv2.weight\n",
      "181 layer4.0.bn2.weight\n",
      "182 layer4.0.bn2.bias\n",
      "183 layer4.0.bn2.running_mean\n",
      "184 layer4.0.bn2.running_var\n",
      "185 layer4.0.bn2.num_batches_tracked\n",
      "31--------\n",
      "186 layer4.0.downsample.0.weight\n",
      "187 layer4.0.downsample.1.weight\n",
      "188 layer4.0.downsample.1.bias\n",
      "189 layer4.0.downsample.1.running_mean\n",
      "190 layer4.0.downsample.1.running_var\n",
      "191 layer4.0.downsample.1.num_batches_tracked\n",
      "32--------\n",
      "192 layer4.1.conv1.weight\n",
      "193 layer4.1.bn1.weight\n",
      "194 layer4.1.bn1.bias\n",
      "195 layer4.1.bn1.running_mean\n",
      "196 layer4.1.bn1.running_var\n",
      "197 layer4.1.bn1.num_batches_tracked\n",
      "33--------\n",
      "198 layer4.1.conv2.weight\n",
      "199 layer4.1.bn2.weight\n",
      "200 layer4.1.bn2.bias\n",
      "201 layer4.1.bn2.running_mean\n",
      "202 layer4.1.bn2.running_var\n",
      "203 layer4.1.bn2.num_batches_tracked\n",
      "34--------\n",
      "204 layer4.2.conv1.weight\n",
      "205 layer4.2.bn1.weight\n",
      "206 layer4.2.bn1.bias\n",
      "207 layer4.2.bn1.running_mean\n",
      "208 layer4.2.bn1.running_var\n",
      "209 layer4.2.bn1.num_batches_tracked\n",
      "35--------\n",
      "210 layer4.2.conv2.weight\n",
      "211 layer4.2.bn2.weight\n",
      "212 layer4.2.bn2.bias\n",
      "213 layer4.2.bn2.running_mean\n",
      "214 layer4.2.bn2.running_var\n",
      "215 layer4.2.bn2.num_batches_tracked\n",
      "36--------\n",
      "216 fc.weight\n",
      "217 fc.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load(\"/home/arnab/Desktop/Data/ResNet34_EPOCH_1_trained_model.pt\")\n",
    "j = 0\n",
    "for i,m in enumerate(model):\n",
    "    if (i)%6 == 0:\n",
    "        print(str(j)+\"--------\")\n",
    "        j += 1\n",
    "    print(i,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load(\"/home/arnab/Desktop/Data/ResNet34_EPOCH_1_trained_model.pt\")\n",
    "\n",
    "# cfgs = [(out_channel,num_model_parameters,stride(optional))]\n",
    "\n",
    "cfgs = [(64,6), (64,12), (64,12), (64,12), (128,18,2), (128,12), (128,12), (128,12), (256,18,2), (256,12), (256,12), (256,12), (256,12), (256,12), (512,18,2), (512,12), (512,12)]\n",
    "\n",
    "\n",
    "def create_model_list(model):\n",
    "    model_list = []\n",
    "    for key in model:\n",
    "        model_list.append(key)\n",
    "        \n",
    "    return model_list\n",
    "\n",
    "def create_model_dict(cfgs,model_list):\n",
    "    model_dict = {}\n",
    "    temp = []\n",
    "    current_model_list_inx = 0\n",
    "    for i,v in enumerate(cfgs):\n",
    "        if len(v) == 2:\n",
    "            out_channel = v[0]\n",
    "            num_model_parameters = v[1]\n",
    "        elif len(v) == 3:\n",
    "            out_channel = v[0]\n",
    "            num_model_parameters = v[1]\n",
    "            stride = v[2]\n",
    "            \n",
    "        for j in range(current_model_list_inx,current_model_list_inx+num_model_parameters):\n",
    "            temp.append(model_list[j])\n",
    "        model_dict.update({i:temp})\n",
    "        #print(\"{}:{}\\n\".format(i,temp))\n",
    "        temp = []\n",
    "        current_model_list_inx += num_model_parameters\n",
    "    return model_dict\n",
    "\n",
    "model_list = create_model_list(model)\n",
    "model_dict = create_model_dict(cfgs,model_list)\n",
    "m = model_dict[0]\n",
    "print(model['fc.bias'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0, 1, 2, 3, 4], 1: [0, 1, 2, 3, 4], 2: [0, 1, 2, 3, 4], 3: [0, 1, 2, 3, 4], 4: [0, 1, 2, 3, 4], 5: [0, 1, 2, 3, 4], 6: [0, 1, 2, 3, 4], 7: [0, 1, 2, 3, 4], 8: [0, 1, 2, 3, 4], 9: [0, 1, 2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "dict_ = {}\n",
    "temp = []\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        temp.append(j)\n",
    "    dict_.update({i:temp})\n",
    "    temp = []\n",
    "print(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['weight'])\n"
     ]
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super(Block, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        \n",
    "        if (in_channels != out_channels) or stride > 1:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, bias = False, stride = stride)\n",
    "            self.bn3= nn.BatchNorm2d(out_channels)\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias = False, stride = stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "net = Block(in_channels=16,out_channels=16)\n",
    "print(net.conv1.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
