{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fog CA: [0.0, 4.0, 6.0]\n",
      "Image Size: torch.Size([BATCH_SIZE, CHANNEL, ROW, COL])\n",
      "\n",
      "torch.Size([1, 3, 224, 224])\n",
      "=> Image : 1\n",
      "=> Convolution Layers: 0\n",
      "\tBefore Conv: torch.Size([1, 3, 90, 224])\n",
      "\tConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 64, 90, 224])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 3, 136, 224])\n",
      "\tConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 64, 136, 224])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 64, 226, 224])\n",
      "=> Convolution Layers: 1\n",
      "\tBefore Conv: torch.Size([1, 64, 91, 224])\n",
      "\tConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 64, 91, 224])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 64, 137, 224])\n",
      "\tConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 64, 137, 224])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 64, 228, 224])\n",
      "=> Convolution Layers: 2\n",
      "\tBefore MaxPool: torch.Size([1, 64, 92, 224])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 64, 46, 112])\n",
      "\n",
      "\tBefore MaxPool: torch.Size([1, 64, 138, 224])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 64, 69, 112])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 64, 115, 112])\n",
      "=> Convolution Layers: 3\n",
      "\tBefore Conv: torch.Size([1, 64, 47, 112])\n",
      "\tConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 128, 47, 112])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 64, 70, 112])\n",
      "\tConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 128, 70, 112])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 128, 117, 112])\n",
      "=> Convolution Layers: 4\n",
      "\tBefore Conv: torch.Size([1, 128, 48, 112])\n",
      "\tConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 128, 48, 112])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 128, 71, 112])\n",
      "\tConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 128, 71, 112])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 128, 119, 112])\n",
      "=> Convolution Layers: 5\n",
      "\tBefore MaxPool: torch.Size([1, 128, 48, 112])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 128, 24, 56])\n",
      "\n",
      "\tBefore MaxPool: torch.Size([1, 128, 73, 112])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 128, 36, 56])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 128, 60, 56])\n",
      "=> Convolution Layers: 6\n",
      "\tBefore Conv: torch.Size([1, 128, 25, 56])\n",
      "\tConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 256, 25, 56])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 128, 37, 56])\n",
      "\tConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 256, 37, 56])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 256, 62, 56])\n",
      "=> Convolution Layers: 7\n",
      "\tBefore Conv: torch.Size([1, 256, 26, 56])\n",
      "\tConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 256, 26, 56])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 256, 38, 56])\n",
      "\tConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 256, 38, 56])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 256, 64, 56])\n",
      "=> Convolution Layers: 8\n",
      "\tBefore Conv: torch.Size([1, 256, 26, 56])\n",
      "\tConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 256, 26, 56])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 256, 40, 56])\n",
      "\tConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 256, 40, 56])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 256, 66, 56])\n",
      "=> Convolution Layers: 9\n",
      "\tBefore MaxPool: torch.Size([1, 256, 27, 56])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 256, 13, 28])\n",
      "\n",
      "\tBefore MaxPool: torch.Size([1, 256, 41, 56])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 256, 20, 28])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 256, 33, 28])\n",
      "=> Convolution Layers: 10\n",
      "\tBefore Conv: torch.Size([1, 256, 14, 28])\n",
      "\tConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 14, 28])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 256, 21, 28])\n",
      "\tConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 21, 28])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 35, 28])\n",
      "=> Convolution Layers: 11\n",
      "\tBefore Conv: torch.Size([1, 512, 15, 28])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 15, 28])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 512, 22, 28])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 22, 28])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 37, 28])\n",
      "=> Convolution Layers: 12\n",
      "\tBefore Conv: torch.Size([1, 512, 16, 28])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 16, 28])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 512, 23, 28])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 23, 28])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 39, 28])\n",
      "=> Convolution Layers: 13\n",
      "\tBefore MaxPool: torch.Size([1, 512, 16, 28])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 512, 8, 14])\n",
      "\n",
      "\tBefore MaxPool: torch.Size([1, 512, 25, 28])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 512, 12, 14])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 20, 14])\n",
      "=> Convolution Layers: 14\n",
      "\tBefore Conv: torch.Size([1, 512, 9, 14])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 9, 14])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 512, 13, 14])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 13, 14])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 22, 14])\n",
      "=> Convolution Layers: 15\n",
      "\tBefore Conv: torch.Size([1, 512, 10, 14])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 10, 14])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 512, 14, 14])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 14, 14])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 24, 14])\n",
      "=> Convolution Layers: 16\n",
      "\tBefore Conv: torch.Size([1, 512, 10, 14])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 10, 14])\n",
      "\n",
      "\tBefore Conv: torch.Size([1, 512, 16, 14])\n",
      "\tConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "\tAfter: torch.Size([1, 512, 16, 14])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 26, 14])\n",
      "=> Convolution Layers: 17\n",
      "\tBefore MaxPool: torch.Size([1, 512, 11, 14])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 512, 5, 7])\n",
      "\n",
      "\tBefore MaxPool: torch.Size([1, 512, 17, 14])\n",
      "\tMaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "\tAfter: torch.Size([1, 512, 8, 7])\n",
      "\n",
      "\tAfter Marge: torch.Size([1, 512, 13, 7])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "=> Fully Connected Layers: \n",
      "\tBefore ff: torch.Size([1, 7168])\n",
      "\tSequential(\n",
      "  (0): Linear(in_features=7168, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=12, bias=True)\n",
      ")\n",
      "\tAfter ff: torch.Size([1, 12])\n",
      "\n",
      "tensor([[0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]], dtype=torch.int32)\n",
      "\n",
      "\tBefore ff: torch.Size([1, 17920])\n",
      "\tSequential(\n",
      "  (0): Linear(in_features=17920, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=12, bias=True)\n",
      ")\n",
      "\tAfter ff: torch.Size([1, 12])\n",
      "\n",
      "tensor([[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]], dtype=torch.int32)\n",
      "\n",
      "Final Feature Classification: tensor([[0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/home/arnab/Desktop/dnn_offloading/Models/bdddataloader.py\")\n",
    "bddloader = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(bddloader)\n",
    "\n",
    "\n",
    "def assign_weight_bias_ff(classifier,model,input_units,prev_input_units):\n",
    "    num_classes = 12\n",
    "    for key,value in classifier.state_dict().items():\n",
    "        k = \"classifier.\" + str(key)\n",
    "        x = key.split(\".\")\n",
    "        if x[1] == \"weight\":\n",
    "            if x[0] == \"0\": # \"1\" to update weight size of first FF layer based on first layer input\n",
    "                weight = model[k]\n",
    "                weight = weight[:,prev_input_units: (prev_input_units + input_units)]\n",
    "                classifier[int(x[0])].weight.data = weight.cpu()\n",
    "            elif x[0] == \"6\": # last linear layer weight row to class_num\n",
    "                weight = model[k]\n",
    "                weight = weight[:num_classes,:]\n",
    "                classifier[int(x[0])].weight.data = weight.cpu()\n",
    "            else:\n",
    "                classifier[int(x[0])].weight.data = model[k].cpu()\n",
    "        elif x[1] == \"bias\":\n",
    "            if x[0] == \"6\": # last linear layer bias to class_num\n",
    "                bias = model[k]\n",
    "                bias = bias[:num_classes]\n",
    "                classifier[int(x[0])].bias.data = bias.cpu()\n",
    "            else:\n",
    "                classifier[int(x[0])].bias.data = model[k].cpu()\n",
    "        \n",
    "    return classifier\n",
    "  \n",
    "in_channel = np.zeros((2),dtype=int) # worker = 2\n",
    "in_channel[0] = 3\n",
    "in_channel[1] = 3\n",
    "prev_input_units = 0\n",
    "def node(NN,img,partition_inx,current_layer,BATCH_SIZE,channel,model,fog_node):\n",
    "    global prev_input_units,in_channel\n",
    "    out_channel = np.zeros((2),dtype=int) # worker = 2\n",
    "    weight = None\n",
    "    bias = None\n",
    "    cfgs = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "    model_list = create_model_list(model)\n",
    "    model_dict = create_model_dict(cfgs,model_list)\n",
    "    if NN == \"conv\":\n",
    "        img_part = adaptive_partitioning(img,partition_inx)\n",
    "        if len(model_dict[current_layer]) > 1:\n",
    "            cfg = model_dict[current_layer][0]\n",
    "            out_channel[fog_node] = model_dict[current_layer][0]\n",
    "            weight = model[model_dict[current_layer][1]]\n",
    "            bias = model[model_dict[current_layer][2]]\n",
    "        else:\n",
    "            cfg = model_dict[current_layer]\n",
    "            \n",
    "        if cfg == 'M':\n",
    "            print(\"\\tBefore MaxPool: {}\".format(img_part.size()))\n",
    "            m = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            print(\"\\t\" + str(m))\n",
    "            return m(img_part)\n",
    "        else:\n",
    "            print(\"\\tBefore Conv: {}\".format(img_part.size()))\n",
    "            m0 = nn.Conv2d(in_channel[fog_node], out_channel[fog_node], kernel_size=3, padding=1)\n",
    "            m1 = nn.ReLU(inplace=True)\n",
    "            print(\"\\t\" + str(m0))\n",
    "            m0.weight.data = weight\n",
    "            m0.bias.data = bias\n",
    "            in_channel[fog_node] = out_channel[fog_node]\n",
    "            return m1(m0(img_part))\n",
    "    elif NN == \"ff\":\n",
    "        num_classes = 12\n",
    "        img_part = adaptive_partitioning(img,partition_inx)\n",
    "        img_part = torch.flatten(img_part,1)\n",
    "        input_units = img_part.shape[1]\n",
    "        print(\"\\tBefore ff: {}\".format(img_part.size()))\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Linear(input_units, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        print(\"\\t\" + str(classifier))\n",
    "        classifier = assign_weight_bias_ff(classifier,model,input_units,prev_input_units)        \n",
    "        prev_input_units = input_units\n",
    "        \n",
    "        return classifier(img_part)\n",
    "        \n",
    "    #print(m.state_dict().keys())\n",
    "    \n",
    "def adaptive_partitioning(img,partition_size):\n",
    "    index = partition_size\n",
    "    temp = img.detach().numpy()\n",
    "    temp = torch.from_numpy(temp[:,:,index[0]:index[1],:])\n",
    "    return temp\n",
    "\n",
    "def partition(NN,img,k,CA,f):\n",
    "    # intializing variables\n",
    "    A = None\n",
    "    partition_size = []\n",
    "    batch = img.shape[0]\n",
    "    channel = img.shape[1]\n",
    "    W = [0] * k  # partition\n",
    "    Windex = []  # partitioning indexes\n",
    "    init = [0] * (k + 1)\n",
    "    CA[0] = 0\n",
    "    CA = [float(val) for val in CA]\n",
    "\n",
    "    r = img.shape[2]\n",
    "    c = img.shape[3]\n",
    "    \n",
    "    if r > c:\n",
    "        m = r\n",
    "    else:\n",
    "        m = c\n",
    "    \n",
    "    \n",
    "    # sum of capabilities of all nodes\n",
    "    C2 = np.sum(CA[:(k + 1)])\n",
    "    \n",
    "    for i in range(1,k+1):\n",
    "        C1 = np.sum(CA[:i+1])\n",
    "        Pi = C1 / C2\n",
    "        if NN == \"conv\":\n",
    "            init[i] = math.floor(Pi * (m - (f - 1)))\n",
    "            partition_size.append((init[i-1],init[i]+(f-1)))\n",
    "        elif NN == \"ff\":\n",
    "            init[i] = math.floor(Pi * m)\n",
    "            partition_size.append((init[i - 1],init[i]))\n",
    "\n",
    "    return partition_size\n",
    "\n",
    "\n",
    "def create_model_list(model):\n",
    "    model_list = []\n",
    "    for key in model:\n",
    "        model_list.append(key)\n",
    "        \n",
    "    return model_list\n",
    "\n",
    "def create_model_dict(cfg,model_list):\n",
    "    model_dict = {}\n",
    "    model_inx = 0\n",
    "    for i,v in enumerate(cfg):\n",
    "        if v != 'M':\n",
    "            model_dict.update({i:(v,model_list[model_inx],model_list[model_inx+1])})\n",
    "            model_inx += 2\n",
    "        else:\n",
    "            model_dict.update({i:v})\n",
    "    return model_dict\n",
    "\n",
    "def main():\n",
    "    # Configuration of network\n",
    "    cfgs = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "    \n",
    "    model = torch.load(\"/home/arnab/Desktop/Data/vgg16.pth\", map_location=torch.device('cpu'))\n",
    "    # Number of workers\n",
    "    worker = 2\n",
    "    \n",
    "    # Capabilities of nodes\n",
    "    #CA = np.random.randint(1, 10, size=k+1)\n",
    "    CA = [0.0, 4.0, 6.0]\n",
    "    print(\"Fog CA: {}\".format(CA))\n",
    "    \n",
    "    # Initialize variables\n",
    "    kernel_filters = 3\n",
    "    num_conv_layer = 5\n",
    "    current_layer = None\n",
    "    partition_list = {}\n",
    "    classify_list = []\n",
    "    after_part = None\n",
    "    input_ = None\n",
    "    channel = None\n",
    "    final_out = None\n",
    "    BATCH_SIZE = 1\n",
    "    IMAGE_DIM = 224\n",
    "    \n",
    "    # load images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(IMAGE_DIM),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "    \n",
    "    loader = data.DataLoader(\n",
    "        bddloader.BDDDataset('/home/arnab/Desktop/Data', train=True, transform=transform),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True)\n",
    "    \n",
    "    \n",
    "    print(\"Image Size: torch.Size([BATCH_SIZE, CHANNEL, ROW, COL])\\n\")\n",
    "    inx = 0\n",
    "    for img,level in loader:\n",
    "        print(img.size())\n",
    "        print(\"=> Image : {}\".format(inx+1))\n",
    "\n",
    "        # Convolutional NN\n",
    "        for i in range(len(cfgs)):\n",
    "            current_layer = i\n",
    "            if i == 0:\n",
    "                input_ = img\n",
    "                channel = input_.shape[1]\n",
    "            else:\n",
    "                input_ = final_out\n",
    "                channel = input_.shape[1]\n",
    "\n",
    "            key = \"Conv\" + str(i)\n",
    "            print(\"=> Convolution Layers: {}\".format(i))\n",
    "            after_part = partition(\"conv\",input_,worker,CA,kernel_filters)\n",
    "            partition_list.update({key : after_part})\n",
    "\n",
    "            # processing and marging\n",
    "            f_inx = None\n",
    "            s_inx = None\n",
    "            final_out = None\n",
    "            for j in range(len(after_part)):\n",
    "                out = node(\"conv\",input_,after_part[j],current_layer,BATCH_SIZE,channel,model,j)\n",
    "                print(\"\\tAfter: {}\\n\".format(out.size()))\n",
    "                if j == 0:\n",
    "                    final_out = out\n",
    "                else:\n",
    "                    final_out = torch.cat((final_out,out),2)\n",
    "                    \n",
    "            print(\"\\tAfter Marge: \" + str(final_out.size()))\n",
    "\n",
    "        \n",
    "        # Adaptive average Pool\n",
    "        avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        out = avgpool(final_out)\n",
    "        print(out.size())\n",
    "        \n",
    "        # Fully Connected NN\n",
    "        current_layer += 1 ## remove later\n",
    "        input_ = out\n",
    "        channel = input_.shape[1]\n",
    "        key = \"ff\"\n",
    "        print(\"=> Fully Connected Layers: \")\n",
    "        after_part = partition(\"ff\",input_,worker,CA,f=0)\n",
    "        partition_list.update({key : after_part})\n",
    "        for j in range(len(after_part)):\n",
    "            out = node(\"ff\",input_,after_part[j],current_layer,BATCH_SIZE,channel,model,j)\n",
    "            print(\"\\tAfter ff: {}\\n\".format(out.size()))\n",
    "            m = nn.ReLU()\n",
    "            out = m(out).data > 0\n",
    "            out = out.int()\n",
    "            classify_list.append(out)\n",
    "            print(\"{}\\n\".format(out))\n",
    "\n",
    "        \n",
    "        classify_final = None\n",
    "        for i in range(len(classify_list)-1):\n",
    "            if i == 0:\n",
    "                classify_final = np.bitwise_or(classify_list[i].numpy()[:], classify_list[i+1].numpy()[:]) \n",
    "            else:\n",
    "                classify_final = np.bitwise_or(classify_final,classify_list[i+1].numpy()[:])\n",
    "\n",
    "        print(\"Final Feature Classification: {}\".format(torch.Tensor(classify_final).double()))\n",
    "        \n",
    "        inx += 1\n",
    "        break # one image break\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
