{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Enter Model Number [1: AlexNet 2: ResNet34 3: VGG16 4: NiN]: 4\n",
      "Number of Epoches: 5\n",
      "Model: NiN\n",
      "Epoch: 1/5\n",
      "\n",
      "Image size: torch.Size([128, 3, 32, 32])\n",
      "Label size: torch.Size([128, 12])\n",
      "Loss: tensor(0.5854, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Total Iterations: 8\n",
      "Epoch: 2/5\n",
      "\n",
      "Loss: tensor(0.5265, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Total Iterations: 16\n",
      "Epoch: 3/5\n",
      "\n",
      "Loss: tensor(0.5443, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Total Iterations: 24\n",
      "Epoch: 4/5\n",
      "\n",
      "Loss: tensor(0.5407, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Total Iterations: 32\n",
      "Epoch: 5/5\n",
      "\n",
      "Loss: tensor(0.5450, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Total Iterations: 40\n",
      "Time:  1.6391909223833256\n"
     ]
    }
   ],
   "source": [
    "# Regarding mean and std: https://stackoverflow.com/questions/57532661/how-do-they-know-mean-and-std-the-input-value-of-transforms-normalize\n",
    "# mean and std calculation: https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560/5\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from torch.utils import data\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "import matplotlib.pyplot as plot\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from utils import load_json\n",
    "import timeit\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"module.name\", \"/home/arnab/Desktop/dnn_offloading/Algorithms/NiN.py\")\n",
    "NiN = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(NiN)\n",
    "\n",
    "# define pytorch device - useful for device-agnostic execution\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \" + str(device))\n",
    "#DEVICE_IDS = 0\n",
    "# Global\n",
    "Model = None\n",
    "all_loss = []\n",
    "epoch_num = []\n",
    "class BDDDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, train, transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.samples = None\n",
    "        self.image_namelist_ = None\n",
    "        self.img_label = None\n",
    "        self.CATEGORY = None\n",
    "        self.LABELS = None\n",
    "        self.category_label()\n",
    "        \n",
    "        if self.train:\n",
    "            self.image_namelist()\n",
    "        else:\n",
    "            self.image_namelist_test()\n",
    "        \n",
    "        self.prepare_data_by_labels()\n",
    "        \n",
    "    def category_label(self):\n",
    "        self.CATEGORY = ['rider', 'traffic light', 'lane', 'traffic sign', 'bike', 'motor', 'truck', 'bus', 'car', 'drivable area', 'person', 'train']\n",
    "        self.LABELS={}\n",
    "        for i,key in enumerate(self.CATEGORY):\n",
    "            self.LABELS.update({key : i})\n",
    "    # train imageList  \n",
    "    def image_namelist(self):\n",
    "        train_label_path = \"/home/arnab/Desktop/Data/labels/bdd1k_labels_images_train.json\"\n",
    "        self.img_label = load_json(train_label_path)\n",
    "        self.image_namelist_ = []\n",
    "        for img in self.img_label:\n",
    "            #print(\"Name: {}\".format(img['name']))\n",
    "            self.image_namelist_.append(img['name'])\n",
    "            \n",
    "    # test imageList\n",
    "    def image_namelist_test(self):\n",
    "        test_label_path = \"/home/arnab/Desktop/Data/labels/bdd1k_labels_images_test.json\"\n",
    "        self.img_label = load_json(test_label_path)\n",
    "        self.image_namelist_ = []\n",
    "        for img in self.img_label:\n",
    "            #print(\"Name: {}\".format(img['name']))\n",
    "            self.image_namelist_.append(img['name'])\n",
    "\n",
    "    # (image->image_stat(label)) is considered\n",
    "    def prepare_data_by_labels(self):\n",
    "        self.samples = []\n",
    "        if self.train:\n",
    "            image_files = glob.glob(\n",
    "                os.path.join(self.root, 'train/*.jpg'))\n",
    "            image_dir = os.path.join(self.root, 'train')\n",
    "        else:\n",
    "            image_files = glob.glob(\n",
    "                os.path.join(self.root, 'test/*.jpg'))\n",
    "            image_dir = os.path.join(self.root, 'test')\n",
    "        \n",
    "        for image_file in self.image_namelist_:\n",
    "            image_path = os.path.join(image_dir,image_file)\n",
    "            for img_stat in self.img_label:\n",
    "                if img_stat['name'] == image_file:\n",
    "                    if os.path.exists(image_path):\n",
    "                        categories_list = []\n",
    "                        categories_list_bool = [0] * len(self.CATEGORY)\n",
    "                        for l in img_stat['labels']:\n",
    "                            categories_list.append(l['category'])\n",
    "                            categories_list = list(set(categories_list))\n",
    "                        for cat in categories_list:\n",
    "                            categories_list_bool[self.LABELS[cat]] = 1\n",
    "                        \n",
    "                        self.samples.append([image_path, torch.Tensor(categories_list_bool)])\n",
    "                    else:\n",
    "                        raise FileNotFoundError\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image_path, img_stat = self.samples[index]\n",
    "\n",
    "        image = pil_loader(image_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_stat\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "\n",
    "\n",
    "# Training the model\n",
    "def Train(model,epoches):\n",
    "    global all_loss,epoch_num\n",
    "    NUM_CLASSES = 12\n",
    "    BATCH_SIZE = 128\n",
    "    EPOCHS = int(epoches)\n",
    "    iterator = 1\n",
    "    \n",
    "    net, transform = Model_Infomation(NUM_CLASSES, model)\n",
    "    loader = data.DataLoader(\n",
    "        BDDDataset('/home/arnab/Desktop/Data/images', train=True, transform=transform),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    Each image data representation: \n",
    "    torch.Size([1, 3, 227, 227])\n",
    "    tensor([[0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.]]) Categories of objects in the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Optimizer and loss function\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    #optimizer = optim.AdamW(net.parameters(), lr=0.001)\n",
    "    #loss_function = nn.MSELoss()\n",
    "    #loss_function = nn.MultiLabelSoftMarginLoss()\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"Epoch: {}/{}\\n\".format(epoch+1,EPOCHS))\n",
    "        for img,label in loader:\n",
    "            if iterator == 1:\n",
    "                print(\"Image size: \" + str(img.shape))\n",
    "                print(\"Label size: \" + str(label.shape))\n",
    "            img,label = img.to(device), label.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(img)\n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iterator += 1\n",
    "        epoch_num.append(epoch+1)\n",
    "        all_loss.append(loss.item())\n",
    "        print(\"Loss: \" + str(loss))\n",
    "        print(\"Total Iterations: \" + str(iterator-1))\n",
    "    torch.save(net.state_dict(),\"/home/arnab/Desktop/Data/NiN_EPOCH_1_trained_model.pt\")\n",
    "        \n",
    "# Calculating accuracy\n",
    "def Accuracy(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    NUM_CLASSES = 12\n",
    "    BATCH_SIZE = 1\n",
    "    \n",
    "    net, transform = Model_Infomation(NUM_CLASSES, model)\n",
    "    net.load_state_dict(torch.load(\"/l/Data/dnn_parameters/trained_model.pt\"))\n",
    "    net.eval()\n",
    "    \n",
    "    test_loader = data.DataLoader(\n",
    "        BDDDataset('/l/Data/images', train=False, transform=transform),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True)\n",
    "    \n",
    "    test_X = []\n",
    "    test_y = []\n",
    "    for X,y in test_loader:\n",
    "        test_X.append(X)\n",
    "        test_y.append(y)\n",
    "    hamming = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            X = test_X[i].to(device)\n",
    "            y = test_y[i]\n",
    "            real_class = y #torch.argmax(test_y[i])\n",
    "            net_out = net(X)#[0]  # returns a list, \n",
    "            predicted_class = net_out.cpu()#torch.argmax(net_out)\n",
    "            #predicted_class = torch.sigmoid(predicted_class).data > 0.5\n",
    "            a = nn.ReLU()\n",
    "            predicted_class = a(predicted_class).data > 0\n",
    "            predicted_class = predicted_class.double()\n",
    "            \n",
    "            # convert from tensor to numpy array\n",
    "            real_class = real_class.numpy()[:]\n",
    "            predicted_class = predicted_class.numpy()[:]\n",
    "\n",
    "            # calculate incorrect classification (n_c)\n",
    "            n_c = np.count_nonzero(real_class!=predicted_class)\n",
    "            #print(n_c)\n",
    "            hamming.append(n_c)\n",
    "            if n_c <= 2:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy: \", round(correct/total, 3)*100)\n",
    "    \n",
    "    \n",
    "def Model_Infomation(NoC,model):\n",
    "    IMAGE_DIM = 0\n",
    "    net = None\n",
    "    if model == \"1\":\n",
    "        IMAGE_DIM = 227\n",
    "        #net = models.alexnet(num_classes=NoC)\n",
    "        net = models.alexnet(num_classes=NoC).to(device)\n",
    "        print(\"Model: AlexNet\")\n",
    "\n",
    "    elif model == \"2\":\n",
    "        IMAGE_DIM = 224\n",
    "        #net = models.resnet34(num_classes=NoC)\n",
    "        net = models.resnet34(num_classes=NoC).to(device)\n",
    "        print(\"Model: ResNet\")\n",
    "\n",
    "    elif model == \"3\":\n",
    "        IMAGE_DIM = 224\n",
    "        #net = models.vgg16(num_classes=NoC)\n",
    "        net = models.vgg16(num_classes=NoC).to(device)\n",
    "        print(\"Model: VGG16\")\n",
    "        \n",
    "    elif model == \"4\":\n",
    "        IMAGE_DIM = 32\n",
    "        net = NiN.NIN(num_classes=NoC)\n",
    "        #net = NiN.NIN(num_classes=NoC).to(device)\n",
    "        print(\"Model: NiN\")\n",
    "        \n",
    "    else:\n",
    "        IMAGE_DIM = 227\n",
    "        #net = models.alexnet(num_classes=NoC)\n",
    "        net = models.alexnet(num_classes=NoC).to(device)\n",
    "        print(\"Model: AlexNet\")\n",
    "        \n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(IMAGE_DIM),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]) # ImageNet dataset normalization\n",
    "    \n",
    "    return net,transform\n",
    "\n",
    "def plot_loss():\n",
    "    global epoch_num,all_loss\n",
    "    plt.plot(epoch_num, all_loss)\n",
    "    # naming the x axis \n",
    "    plt.xlabel('Epoch Number')\n",
    "    # naming the y axis \n",
    "    plt.ylabel('Losses')\n",
    "    \n",
    "def main():\n",
    "    \n",
    "    # Training \n",
    "    # 1: AlexNet \n",
    "    # 2: ResNet34 \n",
    "    # 3: VGG16\n",
    "    # 4: NiN\n",
    "    model = input(\"Enter Model Number [1: AlexNet 2: ResNet34 3: VGG16 4: NiN]: \")\n",
    "    epoches = input(\"Number of Epoches: \")\n",
    "    start = timeit.default_timer()\n",
    "    Train(model,epoches)\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', (stop - start)/60)\n",
    "    \n",
    "    # Accuracy\n",
    "    #Accuracy(model)\n",
    "    \n",
    "    # Plot\n",
    "    #plot_loss()\n",
    "    '''\n",
    "    for param_tensor in net.state_dict():\n",
    "        print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "    '''\n",
    "      \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
